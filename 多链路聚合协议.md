# 1.一些文件汇总
######  1.1 多链路测试基础
![多链路汇聚测试](./attachments/多链路汇聚测试.docx)
###### 1.2 TCP代理思想说明
![TCP代理实现思想说明](./attachments/TCP代理实现思想说明.docx)
###### 1.3 改进设定超时时间的算法
![改进设定时间的超时时间算法](./attachments/改进设定时间的超时时间算法.docx)
###### 1.4 线程池设计
![线程池设计](./attachments/线程池设计.docx)
###### 1.5 SNAT/DNAT
![SNAT并钩包封装发送后，回包不能DNAT的解决记录](./attachments/SNAT并钩包封装发送后，回包不能DNAT的解决记录.docx)

# 2.CentOS环境配置
CentOS6.6普通用户使用sudo命令借用root用户权限:
https://www.cnblogs.com/mengfanrong/p/5206229.html
```bash?linenums
#更新下载源：
cd /etc/yum.repos.d/
mkdir bak
mv * bak/
curl -o /etc/yum.repos.d/CentOS-Base.repo http://file.kangle.odata.cc/repo/Centos-6.repo
curl -o /etc/yum.repos.d/epel.repo http://file.kangle.odata.cc/repo/epel-6.repo
yum clean all
yum makecache
```
CentOS 6安装Linux内核源码：
https://www.linuxidc.com/Linux/2014-10/108768.htm

在CentOS6.5搭建Qt5环境:
https://blog.csdn.net/shine_journey/article/details/50676421
https://blog.csdn.net/m0_37688984/article/details/80216123

# 3.开发板模拟丢包环境搭建
```
板子文件目录：/openwrt/package/base-files/files/root
开机启动文件：/openwrt/package/base-files/files/etc/rc.local
板子镜像文件：/openwrt/bin/targets/ramips/mt7621/openwrt-ramips-mt7621-u7621-06-256M-16M-initramfs-kernel.bin
```
实现模拟丢包：
1.在packetloss文件夹内直接make，将得到的ko文件放在/openwrt/package/base-files/files/root文件夹内
2.在/openwrt文件夹下直接make得到镜像文件/openwrt/bin/targets/ramips/mt7621/openwrt-ramips-mt7621-u7621-06-256M-16M-initramfs-kernel.bin
3.将bin文件复制到pc的D:\TFtpd32.45_downcc文件夹下并改名为test.bin
4.打开tftpd32应用程序选择正确的ip，连接好板子打开mobaX选择正确的串口和波特率57600，命令2为重新烧录。输入板子ip与pc的ip处于同一网段，输入文件名test.bin通过tftpd完成烧录。
5.拔掉网线后，打开mobaX选择正确的串口和波特率115200进入烧录好的系统。进入/root文件夹insmod安装驱动。

实现摄像头：
修改rc.local文件使开机运行run_cam.sh文件，在ubuntu上运行vlc命令，即可将摄像头的内容推流到ubuntu的vlc终端显示。

# 4.调整系统缓冲区
调整系统缓冲区，可提高发送速率和降低丢包率
测试记录：![X710网卡调研](./attachments/X710网卡调研.docx)
```bash?linenums
# rmem_max 接收套接字缓冲区大小的最大值 873200/212992
echo 873200 > /proc/sys/net/core/rmem_max
echo 873200 > /proc/sys/net/core/rmem_default

# wmem_max 发送套接字缓冲区大小的最大值 873200
echo 873200 > /proc/sys/net/core/wmem_max
echo 873200 > /proc/sys/net/core/wmem_default

# 网口接收报文的速率比内核处理的速率快，允许送到队列的数据包的最大数目。
echo 2000 > /proc/sys/net/core/netdev_max_backlog

# socket buffer的最大初始化值 建议保留不变
echo 81920 > /proc/sys/net/core/optmem_max

#set 网卡缓冲区大小
ethtool -G enp45s0f0 rx 4096
ethtool -G enp45s0f0 tx 4096
```
# 5.常见业务端口
测试原理：PC主机需要两个网口，一个网口连接左边路由器的LAN口联通网络，另一个网口连接右边路由器的WAN口，并开启IP转发功能。使手机连接到右边路由器测试不同业务，在PC上用wireshark抓包。
 
 ![端口测试原理图](https://github.com/zjc0000/story_images/raw/main/小书匠/1663638849667.png)
部分测试结果：![常见业务端口部分测试结果](./attachments/常见业务端口.xlsx)
# 6.光模块及PCI-E接口调研

![目前使用的光模块调研](https://github.com/zjc0000/story_images/raw/main/小书匠/1663642512573.png)

![光模块兼容表](https://github.com/zjc0000/story_images/raw/main/小书匠/1663642538447.png)

![PCI-E传输速率](https://github.com/zjc0000/story_images/raw/main/小书匠/1663642614460.png)
# 7.Linux中断
中断是指cpu在执行程序的过程中，出现了某些突发事件急待处理，cpu必需暂停执行当前执行的程序，转去处理突发事件，处理完之后cpu又返回原程序位置并继续执行。
Linux 的中断处理分为顶半部和底半部
顶半部完成尽可能少得的比较紧急的功能，往往只是简单的完成“登记中断”的工作，就是将底半部处理程序挂到该设备的底半部处理队列中去。顶半部中断不可被打断，底半部可以被打断，耗时操作推后执行。

![linux中断处理机制](https://github.com/zjc0000/story_images/raw/main/小书匠/1663643071154.png)
底半部机制：tasklet，工作队列，软中断
软中断和tasklet 运行与软中断上下文，仍属于原子上下文的一种，而工作队列则运行与进程上下文。因此，软中断和tasklet处理函数中不能睡眠，而工作队列处理函数中允许睡眠。
软件意义上的定时器最终依赖硬件定时器来实现，内核在时钟中断发生后检测个定时器释放到期，到期后的定时器处理函数将作为软中断底半部执行。

****参考链接：***
（1）https://www.cnblogs.com/yangtai/p/14922788.html
（2）https://blog.csdn.net/weixin_43839785/article/details/105323842
（3）https://blog.csdn.net/qq_27516841/article/details/122349089*

# 8.工作队列workqueue
内核中通过work_struct结构标识要延迟的工作和要使用的延迟功能。events / X内核线程（每个CPU一个）从工作队列中提取工作，并激活下半部处理程序之一。
内核中有两种工作队列，一种是共享工作队列，另一种是自定义工作队列。

![共享工作队列与自定义共队列的区别](https://github.com/zjc0000/story_images/raw/main/小书匠/1663643234086.png)
共享工作队列：system_wq,每个CPU都有内核提供的系统工作队列。内核中通过work_struct结构标识要延迟的工作和要使用的延迟功能。

![共享工作队列处理机制](https://github.com/zjc0000/story_images/raw/main/小书匠/1663643313424.png)
```c
//共享工作队列使用流程
struct work_struct works;
INIT_WORK(&works,workqueue_fun);
//可以看到内核默认调用的是system_wq
int schedule_work(&works);
/*
int schedule_work(struct work_struct *work)
{
	return queue_work(system_wq, work);
}
*/
```
```c
//自定义工作队列使用流程
struct workqueue_struct  my_workqueue;
struct workqueue_struct *create_workqueue(&my_workqueue);  
//struct workqueue_struct *create_singlethread_workqueue(const char *name);  
//create_workqueue函数会在系统中的每个处理器上创建一个线程（多线程），而create_singlethread_workqueue只是创建一个单一的线程，如果单个线程足够使用，那么应该使用create_singlethread_workqueue函数。
struct work_struct works;
INIT_WORK(&works,workqueue_fun);
int queue_work(struct workqueue_struct *wq, struct work_struct *work);  
int queue_delayed_work(struct workqueue_struct *wq, struct delayed_work *work, unsigned long delay); 
```
****参考链接：***
（1）https://www.cnblogs.com/yangtai/p/14922788.html
（2）https://blog.csdn.net/weixin_43839785/article/details/105323842
（3）https://blog.csdn.net/qq_27516841/article/details/122349089*

# 9.LTE链路模拟/IP隧道实现

![LTE的IP隧道流程](https://github.com/zjc0000/story_images/raw/main/小书匠/1663647472001.png)
LTE环境搭建:![LTE链路 IP隧道实现](./attachments/LTE链路_IP隧道实现.pdf)

# 10.关于网卡检验的测试
目前很多网卡已经支持IP片以及IP/TCP/UDP等协议的校验和计算，用来减少内核层面的运算(减少CPU负载)，当协议层发现网卡支持相应的特性时，会将相应的处理交给网卡操作。如上面提到的校验和，正常情况下，校验和由对应的协议层处理，但在网卡使能情况下会将其推迟到网卡层面处理，网卡处理结束后直接发送。
```bash?linenums
#关闭/开启网卡校验。
ethtoo -K enp4s0f1 tx off/on
#查看网卡支持的特性
ethtoo -k enp4s0f1
```
现象：iperf3进行udp灌包时，在客户端进行抓包，发现UDP校验和是错误的，但仍能发送成功。
原因：网卡开启了UDP校验功能,协议栈调用相关参数没有做UDP校验。使用命令ethtoo -K enp4s0f1 tx off可关闭网卡校验，此时再抓包发现UDP校验是正确的。

现象1：在加载驱动情况下再使用iperf3进行灌包测试，发现无论是否开启关闭网卡校验功能，都必须做IP校验才能成功发送，UDP校验做不做并不影响，此时wireshark抓包发现UDP校验和显示missing,校验状态显示 not present。
现象2：抽离出的仅进行封装和解封的驱动，在f410测试跑4Gbps没有问题，在f408跑300Mbps丢包严重
猜测原因：驱动没有用协议栈函数调用网卡参数而是直接计算校验和，导致必须要自己做校验。但无法解释封包后不做UDP校验仍能成功发送的问题。

下一步调研：
（1）linux协议栈如何做校验，在什么时候做校验？
（2）丢包问题是网卡还是CPU导致?(等新网卡到再进行测试)

# 11.Linux内核对IP分片重组的详细解析
## 11.1 IP分片重组控制信息数据结构
### 11.1.1 网络命名空间struct netns_ipv4
```c
struct net {
...
    struct netns_ipv4	ipv4;
}
struct netns_ipv4 {
...
    struct netns_frags frags;
}
struct netns_frags {
    // 当前保存的所有待重组分片占用的全部内存，不仅仅是分片本身的大小，还有为了管理而增加的额外开销,
    // 该值不允许超过下面的上限值high_thresh，超过后，后续的IP片段将会由于没有内存而被丢弃
    atomic_t mem;
    // 配置参数/proc/sys/net/ipv4/ipfrag_time，默认30s,分片超时时间
    int	timeout;
    // 配置参数/proc/sys/net/ipv4/ipfrag_high_thresh
    int	high_thresh;
...
};
```
### 11.1.2 IPV4协议用于分片重组的全局哈希表信息 struct inet_frags
在内核中同时存在很多需要重组的IP数据包，理论上最大值为1024×128。Linux内核根据接收到的分片的IP头相关信息计算得到一个哈希值，将该值转化到0~1023找到IP分片队列链表。遍历链表找到对应的IP分片队列，若不存在则新建一个IP分片队列。

```c
//哈希值范围0~1023
#define INETFRAGS_HASHSZ	1024
//每个哈希值对应一个IP分片队列链表，该链表最大长度为128,该值会被high_thresh参数影响
#define INETFRAGS_MAXDEPTH	128

//指向IP分片队列链表头
struct hlist_head {
    struct hlist_node *first;
};

struct inet_frag_bucket {
    struct hlist_head	chain;
    spinlock_t	 chain_lock;
};

struct inet_frags {
    // 所有待重组的IP分片队列在该哈希表中
    struct inet_frag_bucket	hash[INETFRAGS_HASHSZ];
...
};
```
### 11.1.3 IP分片队列 struct ipq [struct inet_frag_queue]
```c
//每个ipq结构体表示一个IP分片队列
struct ipq {
    //详细描述IP分片队列中的相关信息
    struct inet_frag_queue q;
...
};

struct hlist_node {
    struct hlist_node *next, **pprev;
};

enum {
    INET_FRAG_FIRST_IN= BIT(0), // 值1，第一个分片
    INET_FRAG_LAST_IN	= BIT(1), // 值2，最后一个分片
    INET_FRAG_COMPLETE= BIT(2), // 值4，全部分片接收完成
};

struct inet_frag_queue {
    struct timer_list	timer;//定时器，超时未重组所有片段会被丢弃
    struct hlist_node	list;// 将IP分片队列接入全局哈希表对应哈希值的IP分片队列链表
    refcount_t		refcnt;//引用计数，每个IP片段都会持有一个该队列的引用计数
    struct sk_buff	*fragments;//始终指向skb队列的队头
    struct sk_buff	*fragments_tail; //目前接收到的最后一个分片，位于skb队列的队尾
    int		len; //当前收到所有IP分片中的最大偏移量
    int		meat;//当前已经收到的IP分片的数据量总和
    __u8      flags;  //记录分片重组的状态，理论上共8种状态
    struct netns_frags *net;// 指向网络命名空间中的net->ipv4.frags
...
};
```
### 11.1.4 上述数据结构之间的关系

![IP分片重组数据结构](https://github.com/zjc0000/story_images/raw/main/小书匠/1663649025103.png)
## 11.2 IP分片重组完整流程
### 11.2.1 IP片段接收入口ip_local_deliver()
 ```c
 int ip_local_deliver(struct sk_buff *skb)
{	
    struct net *net = dev_net(skb->dev);
    //判断数据包是否为一个分组
    if (ip_is_fragment(ip_hdr(skb))) {
	//进行分片重组，ip_defrag成功返回0，需要将最后一个分片skb处理成重组好的包提交
	if (ip_defrag(net, skb, IP_DEFRAG_LOCAL_DELIVER))
		return 0;
	}
    return NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_IN, net, NULL, skb, skb->dev, NULL,ip_local_deliver_finish);
}
#define IP_MF		0x2000
#define IP_OFFSET	0x1FFF
static inline bool ip_is_fragment(const struct iphdr *iph)
{
	//只有当段偏移量为0且MF位为0时说明没有进行分片，此时返回0，否则有分片，此时返回1
	return (iph->frag_off & htons(IP_MF | IP_OFFSET)) != 0;
}
 ```
 ### 11.2.2 IP片段重组 ip_defrag()
 ```c
 int ip_defrag(struct net *net, struct sk_buff *skb, u32 user)
{
    ......
    //查找是否已经在分组队列里存在相应的queue
    //如果没有那么就新建一个queue等待收集之后的报文，如果已经存在那么就返回queue的入口
    qp = ip_find(net, ip_hdr(skb), user, vif);
    if (qp) {
        ......
        // 尝试进行分片重组，如果能够重组出一个完整的IP报文，则返回0，这样数据包就会传递给L4协议
	ret = ip_frag_queue(qp, skb);
        ......
	}
    ......
}
 ```
 ### 11.2.3 查找IP分片队列 ip_find()
```c
static struct ipq *ip_find(struct net *net, struct iphdr *iph,u32 user, int vif)
{
    ......
	// 根据ipid、源IP、目的IP、L4协议号以及初始化时生成的一个随机数共5个信息计算hash值
	hash = ipqhashfn(iph->id, iph->saddr, iph->daddr, iph->protocol);
	// 查找哈希值对应的IP分片队列链表，检查是否有该片段所属报文对应的IP分片队列，如果没有那么函数会新建并将其链表
	q = inet_frag_find(&net->ipv4.frags, &ip4_frags, &arg, hash);
    ......
}

struct inet_frag_queue *inet_frag_find(struct netns_frags *nf,
	struct inet_frags *f, void *key,unsigned int hash)
{
    ......
    //将计算得到的hash值转化到（0~INETFRAGS_HASHSZ - 1）之间，即可找到该hash值对应的IP分片队列链表
    hash &= (INETFRAGS_HASHSZ - 1);
    hb = &f->hash[hash];
    // 遍历IP分片队列链表，寻找匹配的IP分片队列，如果找到增加引用计数并返回
    hlist_for_each_entry(q, &hb->chain, list) {
	if (q->net == nf && f->match(q, key)) {
            refcount_inc(&q->refcnt);
	    spin_unlock(&hb->chain_lock);
	    return q;
	}
	depth++;
    }
    //找不到则创建，IP分片队列总数不能超过最大深度
    if (depth <= INETFRAGS_MAXDEPTH)
	return inet_frag_create(nf, f, key);
    ......
}

static struct inet_frag_queue *inet_frag_create(struct netns_frags *nf,struct inet_frags *f,void *arg)
{
    struct inet_frag_queue *q;
    // 分配IP分片队列并对其进行初始化
    q = inet_frag_alloc(nf, f, arg);
    if (!q)
        	return NULL;
    // 将新建的IP分片队列放入全局的IP分片重组哈希表中
    return inet_frag_intern(nf, q, f, arg);
}
```
### 11.2.4 重组IP报文 ip_frag_queue()
```c
static int ip_frag_queue(struct ipq *qp, struct sk_buff *skb)
{
	struct sk_buff *prev, *next;
	struct net_device *dev;
	unsigned int fragsize;
	int flags, offset;
	int ihl, end;
	int err = -ENOENT;
	u8 ecn;

	//如果IP报文已经重组完成但是又收到属于它的片段，那么一定是重复分片，直接丢弃
	if (qp->q.flags & INET_FRAG_COMPLETE)
		goto err;

	if (!(IPCB(skb)->flags & IPSKB_FRAG_COMPLETE) &&
	    unlikely(ip_frag_too_far(qp)) &&
	    unlikely(err = ip_frag_reinit(qp))) {
		ipq_kill(qp);
		goto err;
	}
	ecn = ip4_frag_ecn(ip_hdr(skb)->tos);


	offset = ntohs(ip_hdr(skb)->frag_off);
	//取得IP分片的相关标志位（&0xe000）
	flags = offset & ~IP_OFFSET;
	//取得IP分片负载第一个字节偏移量，以8字节为单位
	offset &= IP_OFFSET;
	offset <<= 3;	

	ihl = ip_hdrlen(skb);

	/*
	 * IP层分片是对IP的负载进行分片，即只有第一个分片包含L4层头
	 * (skb->len - ihl)是当前分片的IP负载长度与当前分片的偏移量相加
	 * skb_network_offset(skb) = 0，之前的内核版本无此部分
	 * end表示当前分片的负载最后一个字节的偏移量
	*/
	end = offset + skb->len - skb_network_offset(skb) - ihl;
	err = -EINVAL;

	if ((flags & IP_MF) == 0) {
		/*
		 * MF标记为0说明为IP报文的最后一个分片
		 * q.len字段记录的是当前收到所有片段中的最大偏移量，片段到来的顺序是随机的
		*/		
		if (end < qp->q.len ||
		    ((qp->q.flags & INET_FRAG_LAST_IN) && end != qp->q.len))
			goto err;
		
		//标记接收到最后一个片段，更新len字段
		qp->q.flags |= INET_FRAG_LAST_IN;
		qp->q.len = end;
	} else {
		//IP分片不是最后一个分片，则end一定是8字节对齐的，end&7的值一定为0
		if (end&7) {
			end &= ~7;//如果不满足字节对齐，end更新为当前最大的字节对齐数，之后的数据会被丢弃
			//CHECKSUM_NONE表示让L4层重新计算校验和
			if (skb->ip_summed != CHECKSUM_UNNECESSARY)
				skb->ip_summed = CHECKSUM_NONE;
		}
		if (end > qp->q.len) {
			//最后一个分片但其MF标志位不为0，出错
			if (qp->q.flags & INET_FRAG_LAST_IN)
				goto err;
			qp->q.len = end;
		}
	}

	//成立则说明（1）本IP分片没有携带数据（2）携带数据0~7字节被舍弃掉相当于没有数据
	if (end == offset)
		goto err;
	err = -ENOMEM;

	// 调整skb的data指针，删除IP首部，只保留数据部分，此时data指针指向IP头之后的第一个字节，之后所有的字节累计没有重复计算IP头
	if (!pskb_pull(skb, skb_network_offset(skb) + ihl))
		goto err;
	// 截掉字节没有对齐的部分
	err = pskb_trim_rcsum(skb, end - offset);
	if (err)
		goto err;

	//当前分片是第一个分片或应放在当前skb队列最后
	prev = qp->q.fragments_tail;
	if (!prev || FRAG_CB(prev)->offset < offset) {
		next = NULL;
		goto found;
	}

	//根据offset偏移量找到当前分片在skb队列中的位置，应插入prev指针和next指针之间
	prev = NULL;
	for (next = qp->q.fragments; next != NULL; next = next->next) {
		if (FRAG_CB(next)->offset >= offset)
			break;	/* bingo! */
		prev = next;
	}

found:

	//检查新接收分片与应插入skb队列位置前后分片之间的是否存在数据重叠
	//如果出现重叠将队列偏后位置的分片重叠数据进行删除

	//若不是第一个分片则进入if语句
	if (prev) {

		//说明两个报文的负载有重叠，解决办法为将新收到的分片前面一部分删除
		int i = (FRAG_CB(prev)->offset + prev->len) - offset;

		if (i > 0) {
			offset += i;
			err = -EINVAL;
			//说明删除后本分片已经没有数据了
			if (end <= offset)
				goto err;
			err = -ENOMEM;
			//移动data指针，删除前i个字节
			if (!pskb_pull(skb, i))
				goto err;
			if (skb->ip_summed != CHECKSUM_UNNECESSARY)
				skb->ip_summed = CHECKSUM_NONE;
		}
	}


	//循环向后检查新接收的分片与next数据是否有重叠
	while (next && FRAG_CB(next)->offset < end) {
		int i = end - FRAG_CB(next)->offset; 

		if (i < next->len) {
			//说明next末尾有一部分数据是没有重叠的，删除掉重叠的一部分
			if (!pskb_pull(next, i))
				goto err;
			FRAG_CB(next)->offset += i;
			qp->q.meat -= i;
			if (next->ip_summed != CHECKSUM_UNNECESSARY)
				next->ip_summed = CHECKSUM_NONE;
			break;
		} else {
			struct sk_buff *free_it = next;

			//next中所有字节都是重复的，删除next
			next = next->next;

			if (prev)
				prev->next = next;
			else
				qp->q.fragments = next;

			qp->q.meat -= free_it->len;
			sub_frag_mem_limit(qp->q.net, free_it->truesize);
			kfree_skb(free_it);
		}
	}

	FRAG_CB(skb)->offset = offset;

	//将新收到的分片插入到SKB队列中
	skb->next = next;
	if (!next)
		qp->q.fragments_tail = skb;
	if (prev)
		prev->next = skb;
	else
		qp->q.fragments = skb;


	//偏移量为0，说明是第一个分片，更新flags标志
	if (offset == 0)
		qp->q.flags |= INET_FRAG_FIRST_IN;


	// 所有片段都已经收到，重组IP报文
	if (qp->q.flags == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&
	    qp->q.meat == qp->q.len) {
		unsigned long orefdst = skb->_skb_refdst;

		skb->_skb_refdst = 0UL;
		err = ip_frag_reasm(qp, prev, dev);
		skb->_skb_refdst = orefdst;
		return err;
	}
}
```
### 11.2.5 所有分片均已收到重组ip报文 ip_frag_reasm()
```c

static int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,struct net_device *dev)
{
	struct net *net = container_of(qp->q.net, struct net, ipv4.frags);
	struct iphdr *iph;
	struct sk_buff *fp, *head = qp->q.fragments;
	int len;
	int ihlen;
	int err;
	u8 ecn;
	// 将IP分片队列从哈希表中摘下来，递减IP分片队列引用计数，以及停止相关定时器
	ipq_kill(qp);


	//使刚接收到的skb成为分片队列的头，完成重组后skb就是重组好的包。
	//ip_local_deliver函数最后向上层提交的包，就是最后到达的分片，需要将最后一个分片处理成重组好的包提交。
	
	if (prev) {
		head = prev->next;
		//skb_clone是浅拷贝，只克隆了skb结构体部分
		fp = skb_clone(head, GFP_ATOMIC);
		if (!fp)
			goto out_nomem;

		fp->next = head->next;
		if (!fp->next)
			qp->q.fragments_tail = fp;
		prev->next = fp;
		//同样进行了浅拷贝
		skb_morph(head, qp->q.fragments);
		head->next = qp->q.fragments->next;
		//释放了原来分片队列头的skb结构
		consume_skb(qp->q.fragments);
		qp->q.fragments = head;
	}

	// 计算整个IP报文的长度
	ihlen = ip_hdrlen(head);
	len = ihlen + qp->q.len;

	err = -E2BIG;
	// 整个IP报文长度不能超过65535字节
	if (len > 65535)
		goto out_oversize;

	// 第一个IP如果有片段部分，将片段部分先拿出来放到skb链表中之后再连接上，便于后面的操作
	if (skb_has_frag_list(head)) {
		struct sk_buff *clone;
		int i, plen = 0;

		clone = alloc_skb(0, GFP_ATOMIC);
		if (!clone)
			goto out_nomem;
		// 将clone插入到head之后
		clone->next = head->next;
		head->next = clone;
		// 将head的非线性区数据转移到clone的非线性区
		skb_shinfo(clone)->frag_list = skb_shinfo(head)->frag_list;
		skb_frag_list_init(head);
		for (i = 0; i < skb_shinfo(head)->nr_frags; i++)
			plen += skb_frag_size(&skb_shinfo(head)->frags[i]);
		//更新clone和head的相关长度字段
		clone->len = clone->data_len = head->data_len - plen;
		head->data_len -= clone->len;
		head->len -= clone->len;
		//重新计算clone的skb校验和
		clone->csum = 0;
		clone->ip_summed = head->ip_summed;
		add_frag_mem_limit(qp->q.net, clone->truesize);
	}

	// 将所有的IP分片链接到第一个IP片段的frag_list中
	skb_shinfo(head)->frag_list = head->next;
	skb_push(head, head->data - skb_network_header(head));

    //重新计算skb校验和以及长度信息
	for (fp=head->next; fp; fp = fp->next) {
		head->data_len += fp->len;
		head->len += fp->len;
		if (head->ip_summed != fp->ip_summed)
			head->ip_summed = CHECKSUM_NONE;
		else if (head->ip_summed == CHECKSUM_COMPLETE)
			head->csum = csum_add(head->csum, fp->csum);
		head->truesize += fp->truesize;
	}
}
```
***参考链接***
（1）https://blog.csdn.net/wangquan1992/article/details/109228044
（2）https://blog.csdn.net/wangquan1992/article/details/109235276
（3）https://blog.csdn.net/wangpengqi/article/details/9276117
# 12.关于skb结构体的一些整合
## 12.1 skb整体架构

![skb结构体整体架构](https://github.com/zjc0000/story_images/raw/main/小书匠/1663649646811.png)
## 12.2 frags和frag_list的区别
```c
struct skb_shared_info {
...
	struct sk_buff	*frag_list;
	skb_frag_t	frags[MAX_SKB_FRAGS];
};
```
对于frags一般用在当数据真的很多而且在线性数据区域装不下的时候。需要注意的是：只有在DMA支持物理分散页的Scatter/Gather（SG，分散/聚集）操作时候才可以使用frags来保存剩下的数据，否则，**只能扩展线性数据区域进行保存**。

![frags结构示意图](https://github.com/zjc0000/story_images/raw/main/小书匠/1663649755126.png)
对于frag_list来说，一般我们在分片的时候里面装入每个分片的信息，注意，每个分片最终也都是被封装成一个小的skb。

![frag_list结构示意图](https://github.com/zjc0000/story_images/raw/main/小书匠/1663649794992.png)
## 12.3 易混淆：skb结构体中的len和datalen字段
len字段包括线性缓冲区和非线性缓冲区的全部大小，datalen仅为非线性缓冲区大小
```c
skb_headlen(skb) = skb->len - skb->datalen = skb->end - skb->data
```
## 12.4 skb结构体中的ip_summed字段
*在**收包流程**中，ip_summed字段包含了设备驱动告诉L4软件当前校验和的状态，各取值含义如下：*
**CHECKSUM_NONE**：硬件没有提供校验和，可能是硬件不支持，也可能是硬件校验出错但是并未丢弃数据包，而是让L4软件重新校验；
**CHECKSUM_UNNECESSARY**：硬件已经进行了完整的校验，无需软件再进行检查，L4收到数据包后如果检查ip_summed是这种情况，就可以跳过校验过程；
**CHECKSUM_COMPLETE**：硬件已经校验了L4报头和其payload部分，并且校验和保存在了csum中，L4软件只需要再计算伪报头然后检查校验结果即可。

*在**发包流程**中，ip_summed字段包含了L4软件告诉设备驱动程序当前校验和的状态，各取值含义如下：*
**CHECKSUM_NONE**：L4软件已经进行了校验，硬件无需做任何事情；
**CHECKSUM_PARTIAL**：L4软件计算了伪报头，并且将值保存在了首部的check字段中，硬件需要计算其余部分的校验和。
## 12.5 skb结构体中的pkt_type字段
 该字段是根据接收帧MAC地址赋值的，常见有以下几种类型：
 1. **PACKET_HOST**:已接收帧的目的地址就是接收接口
 2. **PACKET_BROADCAST**：已接收的帧的目的地址是接收接口的广播地址
 3. **PACKET_MULTICAST**：已接收的帧的目的地址是该接口已注册的多播地址之一
 4. **PACKET_OTHERHOST**：已接收的帧的目的地址不属于与该接口相匹配的地址
## 12.6 skb_clone()/pskb_copy()/skb_copy()的区别
（1） skb_clone–只复制skb描述符本身，如果只修改skb描述符则使用该函数克隆；
（2） pskb_copy–复制skb描述符+线性数据区域（包括skb_shared_info），如果需要修改描述符以及数据则使用该函数复制；
（3） skb_copy–复制所有数据，包括skb描述符+线性数据区域+非线性数据区，如果需要修改描述符和全部数据则使用该函数复制；
