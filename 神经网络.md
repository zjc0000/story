稀疏矩阵的存储方式

0 1 1 0 0
1 0 1 1 0
1 1 0 1 0
0 1 1 0 1
0 0 0 1 0

coc:
data=\[1 1 1 1 1 1 1 1 1 1 1 1\]
rows=\[0 0 1 1 1 2 2 2 3 3 3 4\]
cols=\[1 2 0 2 3 0 1 3 1 2 4 3\]

csr:
data=\[1 1 1 1 1 1 1 1 1 1 1 1\]
indices=cols=\[1 2 0 2 3 0 1 3 1 2 4 3\]
ind_ptr=\[0 2 5 8 11 12\]
ind_ptr\[i+1\] - ind_ptr\[i\]表示第i行中的数据个数，并且在indices中可读出每个数据的所在列


crc:
data=\[1 1 1 1 1 1 1 1 1 1 1 1\]
indices=cols=\[1 2 0 2 3 0 1 3 1 2 4 3\]
ind_ptr=\[0 2 5 8 11 12\]
ind_ptr\[i+1\] - ind_ptr\[i\]表示第i列中的数据个数，并且在indices中可读出每个数据的所在行

将图应用于机器学习的挑战
1.图缺乏一致的结构
2.每个节点并不是相互独立的，存在连接性
3.图的存储问题，连接性是用邻接矩阵来存储，如果图非常大存储不下来。由于邻接矩阵很稀疏，所以用稀疏矩阵来存储会更好，而稀疏矩阵在GPU上训练一直是个技术难题。
4.置换不变性，邻接矩阵任意交换行列，会导致邻接矩阵改变，他们其实节点关系不变。
节点顺序等变性

图神经网络与图核方法：？


![图神经网络分类](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665814700600.png)
循环图神经网络（RGNN）：假设图中的一个节点不断与其邻居交换信息/消息，直到达到稳定的平衡

卷积图神经网络（CGNN）：是通过汇总节点自身的特征Xv和相邻节点的特征Xu来生成节点v的表征形式
（1）基于谱方法
（2）基于空间方法

（1）节点分类：信息传递，最后的节点能够学习到离它很远邻居节点的特征
![](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665818817431.png)
（2）图分类：通过池化层将图变成子图，从而学习到图高级特征，通过读出层综合这些特征
![](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665818828585.png)

图自动编码器（GAE）：用与获取网络嵌入embedding向量,基于自编码器
![](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665817914133.png)
图自动编码器（VGAE）：图生成：基于变分自编码器（VGAE）

自编码器（AE）：自编码器属于嵌入与表征学习的一种，主要用于数据降维、压缩以及获取低维度表征等。
自编码器可以可以完美的恢复出输入，但是由于损失函数是直接度量重建样本与真实样本的底层特征之间的距离，而不是评价重建样本的逼真度和多样性等抽象指标，在数据生成任务上表现一般。
![](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665818615987.png)
变分自编码器（VAE）：变分自编码器可以定义为一种自编码器，其训练经过正规化以避免过度拟合，并确保隐空间具有能够进行**数据生成过程**的良好属性

时空图神经网络（STGNN）：同时考虑空间依赖性和时间依赖性。许多当前的方法将图卷积与RNN或CNN集成在一起以捕获空间依赖性，从而对时间依赖性进行建模。
用于：交通速度预测，驾驶员操作预期和人类行为识别等
![](https://raw.githubusercontent.com/zjc0000/story_images/main/小书匠/1665819600788.png)

节点级任务：节点回归，节点分类  通过信息传播/图卷积来提取节点高级特征，使用多层感知器或softmax层作为输出层，GNN能够以端到端的方式执行节点级任务。
边级任务：边分类，连接预测  将来自GNN的两个节点的隐藏表征作为输入，可以利用相似度函数或神经网络来预测边的标签/连接强度。
图级任务：图分类(监督学习) 通过池化层将图变成子图，从而学习到图高级特征，通过读出层综合这些特征;图嵌入(无监督学习) 通过图自动编码器或变分图自动编码器

https://zhuanlan.zhihu.com/p/200888266
https://arxiv.org/pdf/1901.00596.pdf#page=18&zoom=100,65,949